{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tdACtNqNmLV"
   },
   "source": [
    "## National Institute of Technology Karnatata, Surathkal\n",
    "## Department of Electronics and Communication Engg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRe54wBGNmLW"
   },
   "source": [
    "## DL Lab : LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Authors : Anirudh BH (16EC105), Manan Sharma (16EC118)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WszawkRNmLZ"
   },
   "source": [
    "Import all Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmDXNmZgNmLb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "\n",
    "#Library to show progress bar and time remaining while training\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#Using sklearn for downloading MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "#Using sklearn for train-test split and to print classification report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbskyD8LQ1xz"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-DuUIyxQzdF"
   },
   "outputs": [],
   "source": [
    "X, Y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUacEyLLt5wG"
   },
   "source": [
    "# Convolutional Layer\n",
    "\n",
    "**Initializer :**<br/>\n",
    "1) in_channel  : Channel Size of the Input<br/>\n",
    "2) out_channel : Channel Size of the Output<br/>\n",
    "3) kernel_size : Filter Size for the kernel<br/>\n",
    "4) stride      : Stride step size for the kernel<br/>\n",
    "5) pad         : Input padding sepcifications. The same number of 0's is padded on both sides<br/>\n",
    "\n",
    "**Methods :** <br/>\n",
    "1) forward : Forward Propogation of the model<br/>\n",
    "2) backward : Backward Propogation of the Loss and Gradient Descent Update<br/>\n",
    "3) zero_pad : Padding the inuput to preserve/expand dimensions<br/>\n",
    "4) cov_single_step : The main function for the forward convolution of a given windowed input. Window size = kernel filter size<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSZENSDa5Cxb"
   },
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, pad):\n",
    "        # Current Implementation is targeted square filters\n",
    "        assert type(kernel_size) == int , \"Kernel Error, Enter a scalar of type Int\" \n",
    "        # Initialze the weights and bias associated with the layer\n",
    "        self.W = np.random.randn(kernel_size, kernel_size, in_channel, out_channel).astype(float)\n",
    "        self.b = np.random.randn(1,1,1,out_channel).astype(float)\n",
    "        # Class Attributes\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.pad = pad \n",
    "\n",
    "    def zero_pad(self, X):\n",
    "        '''\n",
    "        Input\n",
    "        X : Input from the previous layer/Original Image input\n",
    "        \n",
    "        Output\n",
    "        X_pad : Padded version of the input\n",
    "        \n",
    "        Operation\n",
    "        Pad both sides of the input X with the specified number of zeros\n",
    "        '''\n",
    "        X_pad = np.pad(X,((0,0),(self.pad,self.pad), (self.pad,self.pad),(0,0)), mode='constant', constant_values = (0,0))\n",
    "        return X_pad\n",
    "\n",
    "    def conv_single_step(self, a_slice_prev, weights, bias):\n",
    "        '''\n",
    "        Inputs\n",
    "        a_slice_prev : The windowed version of the input. Window Length = filter size\n",
    "        weights      : The filter kernel for the input. Size = kernel_size, kernel_size, in_channel\n",
    "        bias         : Bias associated with the filter\n",
    "        \n",
    "        Output\n",
    "        Z : Output of the convolution operation\n",
    "        \n",
    "        Operation\n",
    "        Pointwise-multiplication of the sliced input and the filter. \n",
    "        The elements of the multiplied output is summed and the bias term is added\n",
    "        '''\n",
    "        s = a_slice_prev* weights\n",
    "        Z = np.sum(s)\n",
    "        Z = Z + float(bias)\n",
    "        return Z\n",
    "\n",
    "    def forward(self, A_prev):\n",
    "        '''\n",
    "        Input\n",
    "        A_prev : The input to the current layer(output of the previous layer + activation)\n",
    "        \n",
    "        Output\n",
    "        Z : The output of the 2D linear Convolution operation\n",
    "        \n",
    "        Operation\n",
    "        First the input is windowed/sliced. The window length used is specified from the Initializer\n",
    "        The sliced input is taken and a single filter is applied . The output is a single entry into the output array\n",
    "        This step is repeated for all channels. A total of out_channel number of filters are present\n",
    "        The above step is then repeated for all the rows and columns of the output array\n",
    "        \n",
    "        Note: We store the input to the layer as well for backprop\n",
    "        '''\n",
    "        (m, n_H_prev, n_W_prev, _) = A_prev.shape \n",
    "        n_H = int((n_H_prev - self.kernel_size + 2 * self.pad) / self.stride) + 1\n",
    "        n_W = int((n_W_prev - self.kernel_size + 2 * self.pad) / self.stride) + 1\n",
    "        Z = np.zeros((m, n_H, n_W, self.out_channel))\n",
    "        if self.pad == 0:\n",
    "            A_prev_pad = A_prev\n",
    "        else:\n",
    "            A_prev_pad = self.zero_pad(A_prev)\n",
    "        \n",
    "        for i in range(m):\n",
    "            a_prev_pad = A_prev_pad[i,:,:,:]\n",
    "            for h in range(n_H):\n",
    "                vert_start = h * self.stride\n",
    "                vert_end = vert_start + self.kernel_size\n",
    "                \n",
    "                for w in range(n_W):\n",
    "                    horiz_start = w * self.stride\n",
    "                    horiz_end = horiz_start + self.kernel_size\n",
    "                    \n",
    "                    for c in range(self.out_channel):\n",
    "                        a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                        weights = self.W[...,c]\n",
    "                        biases = self.b[...,c]\n",
    "                        Z[i, h, w, c] = self.conv_single_step(a_slice_prev, weights, biases)\n",
    "        assert(Z.shape == (m, n_H, n_W, self.out_channel))\n",
    "        self.prev = A_prev\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, dZ, learning_rate=0.001):\n",
    "        '''\n",
    "        Input\n",
    "        dZ : Derivative of the Loss function wrt the output of the current layer\n",
    "        learning_rate : The step size for the gradient update.\n",
    "        \n",
    "        Output\n",
    "        dA_prev : The derivative of the loss function wrt the previous layer output\n",
    "        \n",
    "        Operation\n",
    "        The derivative of the loss wrt the previous layer's ouput is caculated from the derivative wrt the output of the current layer\n",
    "        This is calculated using the Chain Rule\n",
    "        Along with the derivative wrt the previous layer, the deriavte wrt the weights and bias of the current layer is calculated\n",
    "        The calculated weight and bias gradients are used for the gradient descent update\n",
    "        \n",
    "        Stored Values from Forward Propogation\n",
    "        self.prev : Input to the current layer for forward propogation\n",
    "        '''\n",
    "        A_prev = self.prev\n",
    "        (m, n_H_prev, n_W_prev, _) = A_prev.shape\n",
    "        (m, n_H, n_W, _) = dZ.shape\n",
    "        dA_prev = np.zeros((m, n_H_prev, n_W_prev, self.in_channel))   \n",
    "        dW = np.zeros((self.kernel_size, self.kernel_size, self.in_channel, self.out_channel))\n",
    "        db = np.zeros((1, 1, 1, self.out_channel))\n",
    "        if self.pad == 0:\n",
    "            A_prev_pad = A_prev\n",
    "            dA_prev_pad = dA_prev\n",
    "        else:\n",
    "            A_prev_pad = self.zero_pad(A_prev)\n",
    "            dA_prev_pad = self.zero_pad(dA_prev)\n",
    "        \n",
    "        for i in range(m):\n",
    "            a_prev_pad = A_prev_pad[i]\n",
    "            da_prev_pad = dA_prev_pad[i]\n",
    "            \n",
    "            for h in range(n_H):\n",
    "                for w in range(n_W):\n",
    "                    for c in range(self.out_channel):\n",
    "                        vert_start = h * self.stride\n",
    "                        vert_end = vert_start + self.kernel_size\n",
    "                        horiz_start = w * self.stride\n",
    "                        horiz_end = horiz_start + self.kernel_size\n",
    "                        a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end,:]\n",
    "                        da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += self.W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                        dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                        db[:,:,:,c] += dZ[i, h, w, c]\n",
    "            if self.pad == 0:\n",
    "                dA_prev[i, :, :, :] = da_prev_pad\n",
    "            else :\n",
    "                dA_prev[i, :, :, :] = da_prev_pad[self.pad:-self.pad, self.pad:-self.pad, :]\n",
    "        assert(dA_prev.shape == (m, n_H_prev, n_W_prev, self.in_channel))\n",
    "        self.W -= learning_rate * dW\n",
    "        self.b -= learning_rate * db\n",
    "        return dA_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70fg4v2PRFS5"
   },
   "source": [
    "# Pooling Layer\n",
    "\n",
    "**Initializer :**<br/>\n",
    "1) kernel_size : Filter Size for the kernel<br/>\n",
    "2) stride      : Stride step size for the kernel<br/>\n",
    "3) mode        : Pooling type sepcifications<br/>\n",
    "\n",
    "**Methods :** <br/>\n",
    "1) forward : Forward Propogation of the model<br/>\n",
    "2) backward : Backward Propogation of the Loss and Gradient Descent Update<br/>\n",
    "3) create_mask_from_window : Create the mask to find the max element for backprop of Max Pool<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4SRIvFU1r3h"
   },
   "outputs": [],
   "source": [
    "class PoolLayer:\n",
    "    def __init__(self, kernel_size, stride, mode = 'max'):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        # mode can only be average or max\n",
    "        self.mode = mode\n",
    "\n",
    "    def create_mask_from_window(self, x):\n",
    "        '''\n",
    "        Input\n",
    "        x : Sliced/Windowed Input\n",
    "        \n",
    "        Output\n",
    "        A mask with the index of the max element as 1 and remaining elments as 0\n",
    "        \n",
    "        Operation\n",
    "        Returns an mask/array of the same dimensions as the input\n",
    "        The array has a value of 1 at the position of the maximum element and 0 otherwise\n",
    "        It is essential for max pooling. It is not used in the average pooling mode\n",
    "        '''\n",
    "        return (x==np.max(x)).astype(float)\n",
    "    \n",
    "    def forward(self, A_prev):\n",
    "        '''\n",
    "        Input\n",
    "        A_prev : The input to the current layer(output of the previous layer + activation)\n",
    "        \n",
    "        Output\n",
    "        A : The output of the 2D Max/Avg Pooling operation\n",
    "        \n",
    "        Operation\n",
    "        First the input is windowed/sliced. The window length used is specified from the Initializer\n",
    "        The sliced input is either averaged or the maximum element is taken depending on the mode\n",
    "        The above step is then repeated for all the entire input array\n",
    "        \n",
    "        Note: We store the input to the layer as well for backprop\n",
    "        '''\n",
    "        (m, n_H_prev, n_W_prev, n_C) = A_prev.shape\n",
    "        n_H = int(1 + (n_H_prev - self.kernel_size) / self.stride)\n",
    "        n_W = int(1 + (n_W_prev - self.kernel_size) / self.stride)\n",
    "        A = np.zeros((m, n_H, n_W, n_C))              \n",
    "\n",
    "        for i in range(m):\n",
    "            for h in range(n_H):\n",
    "                vert_start = h*self.stride\n",
    "                vert_end = vert_start + self.kernel_size\n",
    "                \n",
    "                for w in range(n_W):\n",
    "                    horiz_start = w * self.stride\n",
    "                    horiz_end = horiz_start + self.kernel_size\n",
    "                    \n",
    "                    for c in range (n_C):\n",
    "                        a_prev_slice = A_prev[i,vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                        if self.mode == \"max\":\n",
    "                            A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                        elif self.mode == \"average\":\n",
    "                            A[i, h, w, c] = np.mean(a_prev_slice)        \n",
    "        assert(A.shape == (m, n_H, n_W, n_C))\n",
    "        self.prev = A_prev\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA, **kwargs):\n",
    "        '''\n",
    "        Input\n",
    "        dA : Derivative of the Loss function wrt the output of the current layer\n",
    "        \n",
    "        Output\n",
    "        dA_prev : The derivative of the loss function wrt the previous layer output\n",
    "        \n",
    "        Operation\n",
    "        The derivative of the loss wrt the previous layer's ouput is caculated from the derivative wrt the output of the current layer\n",
    "        This is calculated using the Chain Rule\n",
    "        \n",
    "        Stored Values from Forward Propogation\n",
    "        self.prev : Input to the current layer for forward propogation\n",
    "        '''\n",
    "        A_prev = self.prev\n",
    "        m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "        m, n_H, n_W, n_C = dA.shape\n",
    "        dA_prev = np.zeros_like(A_prev)\n",
    "        for i in range(m):\n",
    "            a_prev = A_prev[i]\n",
    "            \n",
    "            for h in range(n_H):\n",
    "                for w in range(n_W):\n",
    "                    for c in range(n_C):\n",
    "                        vert_start = h * self.stride\n",
    "                        vert_end = vert_start + self.kernel_size\n",
    "                        horiz_start = w * self.stride\n",
    "                        horiz_end = horiz_start + self.kernel_size\n",
    "                        if self.mode == \"max\":\n",
    "                            a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                            mask = self.create_mask_from_window(a_prev_slice)\n",
    "                            dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += mask * dA[i,h,w,c]\n",
    "                            \n",
    "                        elif self.mode == \"average\":\n",
    "                            da = dA[i,h,w,c]\n",
    "                            shape = (self.kernel_size, self.kernel_size)\n",
    "                            dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)        \n",
    "        assert(dA_prev.shape == A_prev.shape)\n",
    "        return dA_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtHyjmwGRJn4"
   },
   "source": [
    "# Linear Layer\n",
    "\n",
    "**Initializer :**<br/>\n",
    "1) input_dim  : Input Dimension Length<br/>\n",
    "2) output_dim : Output Dimension Length<br/>\n",
    "\n",
    "**Methods :** <br/>\n",
    "1) forward : Forward Propogation of the model<br/>\n",
    "2) backward : Backward Propogation of the Loss and Gradient Descent Update<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfwbkEcePZ0o"
   },
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        # Initialize the weights and bias for the layer\n",
    "        self.W = np.random.randn(input_dim, output_dim)\n",
    "        self.b = np.zeros(output_dim, dtype=float)\n",
    "\n",
    "    def forward(self, A_prev):\n",
    "        '''\n",
    "        Input\n",
    "        A_prev : The input to the current layer(output of the previous layer + activation)\n",
    "        \n",
    "        Output\n",
    "        The output of the Dense Layer aka Linear Layer\n",
    "        \n",
    "        Operation\n",
    "        The Input is Matrix Multiplied with a matrix of dims (input_dim, output_dim)\n",
    "        The Input is transformed from the input_dim space to the output_dim space\n",
    "        \n",
    "        Note: We store the input to the layer as well for backprop\n",
    "        '''\n",
    "        self.A_prev = A_prev\n",
    "        return np.add((A_prev @ self.W), self.b)\n",
    "\n",
    "    def backward(self, dA, learning_rate=0.001):\n",
    "        '''\n",
    "        Input\n",
    "        dA : Derivative of the Loss function wrt the output of the current layer\n",
    "        learning_rate : The step size for the gradient update.\n",
    "        \n",
    "        Output\n",
    "        dA_prev : The derivative of the loss function wrt the previous layer output\n",
    "        \n",
    "        Operation\n",
    "        The derivative of the loss wrt the previous layer's ouput is caculated from the derivative wrt the output of the current layer\n",
    "        This is calculated using the Chain Rule\n",
    "        Along with the derivative wrt the previous layer, the deriavte wrt the weights and bias of the current layer is calculated\n",
    "        The calculated weight and bias gradients are used for the gradient descent update\n",
    "        \n",
    "        Stored Values from Forward Propogation\n",
    "        self.prev : Input to the current layer for forward propogation\n",
    "        '''\n",
    "        dW = (self.A_prev).T @ dA\n",
    "        db = np.sum(dA,axis=0) \n",
    "        dA_prev = dA @ (self.W).T\n",
    "        self.W -= learning_rate*dW\n",
    "        self.b -= learning_rate*db\n",
    "        return dA_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxBt2LrkRLGx"
   },
   "source": [
    "# Non-Trainable Layers\n",
    "\n",
    "Flattening and Activation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWWAe0Evgowh"
   },
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def forward(self, A_prev):\n",
    "        # Remember the input dim for backprop\n",
    "        self.dim = A_prev.shape[1:]\n",
    "        # Flatten all dims, except the batch dim\n",
    "        return np.reshape(A_prev, (-1, np.prod(self.dim)))\n",
    "\n",
    "    def backward(self, dA, *args, **kwargs):\n",
    "        # Reshape the gradient to the original input dim\n",
    "        return np.reshape(dA, (-1, *(self.dim)))\n",
    "\n",
    "class Sigmoid:\n",
    "    def forward(self, A_prev):\n",
    "        # Calculate and store the output of the sigmoid\n",
    "        self.out = 1/(1+np.exp(-1*A_prev))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dA, *args, **kwargs):\n",
    "        # From the stored output, Calculate the gradient prior to the activation\n",
    "        return dA*self.out*(1.0-self.out)\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        # Very small value to prevent NaN and +-Inf\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, A_prev):\n",
    "        # Perform the ReLU operation\n",
    "        out = np.maximum(A_prev, 0)\n",
    "        # Store the mask where input was greater than 1 for backprop\n",
    "        self.mask = (out > 0).astype(float)\n",
    "        return out + self.epsilon\n",
    "\n",
    "    def backward(self, dA, *args, **kwargs):\n",
    "        # Using the mask calculate the gradient prior to the actiavtion\n",
    "        return self.mask*dA + self.epsilon\n",
    "\n",
    "class Softmax:\n",
    "    def forward(self, A_prev):\n",
    "        # Compute the softmax of vector x\n",
    "        exps = np.exp(A_prev - A_prev.max(axis=1))\n",
    "        return exps / np.sum(exps, axis = 1)\n",
    "\n",
    "    def backward(self, dA, *args, **kwargs):\n",
    "        return dA*(1.0-dA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iVyLaTQWFvv"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UiXuwOQdQbH"
   },
   "source": [
    "## Data Split and Limit\n",
    "\n",
    "We limit the Data due to the excessive duration of execution for the entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBevAAtgdorG"
   },
   "outputs": [],
   "source": [
    "limit_data = 6000\n",
    "X = X[0:limit_data,]\n",
    "Y = Y[0:limit_data]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X/255, Y.astype(float), test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DfWE1MYgdaLj"
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "Since the Model is a Sequential Model, we save it as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pSPzKg0dpDk"
   },
   "outputs": [],
   "source": [
    "model = [ConvLayer(in_channel = 1, out_channel=6, kernel_size=5, stride = 1, pad = 2), \n",
    "        Sigmoid(), \n",
    "        PoolLayer(kernel_size = 2, stride = 2),\n",
    "        ConvLayer(in_channel = 6, out_channel=16, kernel_size=5, stride = 1, pad = 0), \n",
    "        Sigmoid(), \n",
    "        PoolLayer(kernel_size = 2, stride = 2),\n",
    "        Flatten(),\n",
    "        LinearLayer(input_dim = 5*5*16, output_dim = 120),\n",
    "        Sigmoid(),\n",
    "        LinearLayer(input_dim = 120, output_dim = 84),\n",
    "        Sigmoid(),\n",
    "        LinearLayer(input_dim = 84, output_dim = 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax and Softmax Derivative Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOTlEncBn_-P"
   },
   "outputs": [],
   "source": [
    "def stable_softmax(X):\n",
    "    exps = np.exp(X - np.max(X, axis=1))\n",
    "    return exps / np.sum(exps, axis=1)\n",
    "\n",
    "def cross_entropy(X,y):\n",
    "    # X is the output from fully connected layer (num_examples x num_classes)\n",
    "    # y is labels (num_examples x 1). y is not one-hot encoded vector. \n",
    "    m = y.shape[0]\n",
    "    p = stable_softmax(X)\n",
    "    # We use multidimensional array indexing to extract \n",
    "    # softmax probability of the correct label for each sample.\n",
    "    # Refer to https://docs.scipy.org/doc/numpy/user/basics.indexing.html#indexing-multi-dimensional-arrays for understanding multidimensional array indexing.\n",
    "    log_likelihood = -np.log(p[range(m),y.astype(int)])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n",
    "\n",
    "def delta_cross_entropy(X,y):\n",
    "    # X is the output from fully connected layer (num_examples x num_classes)\n",
    "    # y is labels (num_examples x 1). Note that y is not one-hot encoded vector. \n",
    "    m = y.shape[0]\n",
    "    grad = stable_softmax(X)\n",
    "    grad[range(m),y.astype(int)] -= 1\n",
    "    grad = grad/m\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJyFjfxNdcKX"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a129cc23368f42e6a4984c3856151768",
      "d4783a4da9464489a9de103a8b1e29f0",
      "342bcc9d813a45e5ba5e508e971a2778",
      "02bd46670bb84d1c91cf1b3caa0c7e24",
      "e2fcdf429f2b4e179189fc19b5fde704",
      "dc21b29d7f9541e9be6fe4747b6604ac",
      "8441c2a371e14f8e85ff8ba166884fbd",
      "7910066bb3434834b9b6d31fd45b8d64"
     ]
    },
    "colab_type": "code",
    "id": "_kWI7CNvlaxI",
    "outputId": "ac4fec5e-97cd-4688-aed9-a354bc96adc5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a7daa6084a484ab97edb78946ab763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  1 Loss :  1.6697436938197052 Accuracy :  0.441875\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c8279f27f84aca81aca07e2a51f430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  2 Loss :  1.0333770750323388 Accuracy :  0.6677083333333333\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f606643cb29475786fa0e3800b0d7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  3 Loss :  0.7654709857974423 Accuracy :  0.7641666666666667\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455066677c974255830a5c62c510f693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  4 Loss :  0.6152362617739958 Accuracy :  0.8102083333333333\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c89d4c5c16d4cd39f90126aa8c1dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  5 Loss :  0.5293232502180545 Accuracy :  0.8370833333333333\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b2782d0fb647338e8ae2bd20adb4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  6 Loss :  0.47085819563616865 Accuracy :  0.8558333333333333\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f06a19a21a4de1ac08da1df8c62df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  7 Loss :  0.4253930055894171 Accuracy :  0.8685416666666667\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d5184d735e4febb689868a9a34b119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  8 Loss :  0.3892037183194111 Accuracy :  0.8804166666666666\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1034507758240839386906d16fe5c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  9 Loss :  0.35794006238397336 Accuracy :  0.8885416666666667\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2e576ce6d641a99179d327175a0a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  10 Loss :  0.3309789788246058 Accuracy :  0.8964583333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_length = len(X_train)\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    loss_epoch = 0 \n",
    "    accuracy = 0\n",
    "    for input_data, label in tqdm(zip(X_train, Y_train), total = train_length):\n",
    "        input_data = input_data.reshape(1,28,28,1)\n",
    "        label = np.array([label])\n",
    "        label_oh = (np.eye(10)[label.astype(int)]).reshape(1,10)\n",
    "        # Forward Propogation\n",
    "        output = input_data.copy()\n",
    "        for layer in model:\n",
    "            output = layer.forward(output)\n",
    "        # Cross entropy Loss\n",
    "        assert output.shape == label_oh.shape, \"Network Output and Label Dim Don't Match\"\n",
    "        loss_epoch += cross_entropy(output,label)\n",
    "        # Accuracy Check\n",
    "        accuracy += np.mean(label == np.argmax(output, axis=1))\n",
    "        # Backward Propogation, Weight Updation occurs with the classes\n",
    "        backprop_out = delta_cross_entropy(output,label)\n",
    "        for layer in model[::-1]:\n",
    "            backprop_out = layer.backward(backprop_out, learning_rate=0.005)\n",
    "    loss_list.append(loss_epoch)\n",
    "    print(\"Epoch : \", epoch+1, 'Loss : ', loss_epoch/train_length, 'Accuracy : ', accuracy/train_length)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e216b23da0634b9a8f5e7a69cb96e987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  11 Loss :  0.30754601059890146 Accuracy :  0.9035416666666667\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4f403b09164006afe45c87b322e7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  12 Loss :  0.2861770225389345 Accuracy :  0.9125\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffa314ba08643dabbe2d28347f0ef0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  13 Loss :  0.2667843124947442 Accuracy :  0.91875\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745d1f3a245649cbb1d97f9c990782c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  14 Loss :  0.24961214871633985 Accuracy :  0.9254166666666667\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa39e1d7d0c14113a966904c5251cf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  15 Loss :  0.23451037792184143 Accuracy :  0.9304166666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training for 5 more epochs\n",
    "num_epochs = 15\n",
    "resume_epoch = 10\n",
    "train_length = len(X_train)\n",
    "for epoch in range(resume_epoch, num_epochs):\n",
    "    loss_epoch = 0 \n",
    "    accuracy = 0\n",
    "    for input_data, label in tqdm(zip(X_train, Y_train), total = train_length):\n",
    "        input_data = input_data.reshape(1,28,28,1)\n",
    "        label = np.array([label])\n",
    "        label_oh = (np.eye(10)[label.astype(int)]).reshape(1,10)\n",
    "        # Forward Propogation\n",
    "        output = input_data.copy()\n",
    "        for layer in model:\n",
    "            output = layer.forward(output)\n",
    "        # Cross entropy Loss\n",
    "        assert output.shape == label_oh.shape, \"Network Output and Label Dim Don't Match\"\n",
    "        loss_epoch += cross_entropy(output,label)\n",
    "        # Accuracy Check\n",
    "        accuracy += np.mean(label == np.argmax(output, axis=1))\n",
    "        # Backward Propogation, Weight Updation occurs with the classes\n",
    "        backprop_out = delta_cross_entropy(output,label)\n",
    "        for layer in model[::-1]:\n",
    "            backprop_out = layer.backward(backprop_out, learning_rate=0.005)\n",
    "    loss_list.append(loss_epoch)\n",
    "    print(\"Epoch : \", epoch+1, 'Loss : ', loss_epoch/train_length, 'Accuracy : ', accuracy/train_length)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabe41b511164e91bc3817cd4d2fddd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  16 Loss :  0.22174170549462643 Accuracy :  0.934375\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58669da4223f477a998c3822fa60ee89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  17 Loss :  0.20999103809021658 Accuracy :  0.9397916666666667\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9abcc9026fd4c3daa020c251a90440e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  18 Loss :  0.19924805037094914 Accuracy :  0.9414583333333333\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183e49d938fc4d4cb142c69530a54953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  19 Loss :  0.1896234735027401 Accuracy :  0.9435416666666666\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dee77408ba14dcbbf2c0f8206257a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch :  20 Loss :  0.18063247390368198 Accuracy :  0.9472916666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training for 5 more epochs\n",
    "num_epochs = 20\n",
    "resume_epoch = 15\n",
    "train_length = len(X_train)\n",
    "for epoch in range(resume_epoch, num_epochs):\n",
    "    loss_epoch = 0 \n",
    "    accuracy = 0\n",
    "    for input_data, label in tqdm(zip(X_train, Y_train), total = train_length):\n",
    "        input_data = input_data.reshape(1,28,28,1)\n",
    "        label = np.array([label])\n",
    "        label_oh = (np.eye(10)[label.astype(int)]).reshape(1,10)\n",
    "        # Forward Propogation\n",
    "        output = input_data.copy()\n",
    "        for layer in model:\n",
    "            output = layer.forward(output)\n",
    "        # Cross entropy Loss\n",
    "        assert output.shape == label_oh.shape, \"Network Output and Label Dim Don't Match\"\n",
    "        loss_epoch += cross_entropy(output,label)\n",
    "        # Accuracy Check\n",
    "        accuracy += np.mean(label == np.argmax(output, axis=1))\n",
    "        # Backward Propogation, Weight Updation occurs with the classes\n",
    "        backprop_out = delta_cross_entropy(output,label)\n",
    "        for layer in model[::-1]:\n",
    "            backprop_out = layer.backward(backprop_out, learning_rate=0.005)\n",
    "    loss_list.append(loss_epoch)\n",
    "    print(\"Epoch : \", epoch+1, 'Loss : ', loss_epoch/train_length, 'Accuracy : ', accuracy/train_length)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PiymY_qPebu2"
   },
   "source": [
    "# Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "j-hO0eiKedbS",
    "outputId": "bb8e9460-9073-44ef-d58b-88d4e3cac3fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,21), loss_list)\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9wcesjOYeaiT"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "a4c348bc738a483f8dafdd01bc6cf7ed",
      "fa74b47a01c842e9ad2352f42fd49944",
      "0f853f38f1444a678d71917f339b73fe",
      "a37011d0c0f04548a748d2b18785ec96",
      "1c1954630645448795cda910c64a2e8f",
      "0d1981de55af4c088695ea8a55076bfb",
      "63c02eeff8074881bbb2ccb6fc3c35b8",
      "243f976ef6d440189e00df97f0cf467c"
     ]
    },
    "colab_type": "code",
    "id": "o9O4adVhD0Ev",
    "outputId": "548d7791-81e2-4886-b766-88273275131d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy :  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "test_length = len(X_test)\n",
    "loss = 0 \n",
    "accuracy = 0\n",
    "gt_list = []\n",
    "pred_list = []\n",
    "for input_data, label in zip(X_test, Y_test):\n",
    "    input_data = input_data.reshape(1,28,28,1)\n",
    "    label = np.array([label])\n",
    "    label_oh = (np.eye(10)[label.astype(int)]).reshape(1,10)\n",
    "    # Forward Propogation\n",
    "    output = input_data.copy()\n",
    "    for layer in model:\n",
    "        output = layer.forward(output)\n",
    "    assert output.shape == label_oh.shape, \"Network Output and Label Dim Don't Match\"\n",
    "    # Accuracy Check\n",
    "    accuracy += np.mean(label == np.argmax(output, axis=1))\n",
    "    gt_list.append(label)\n",
    "    pred_list.append(np.argmax(output,axis=1))\n",
    "print('Test accuracy : ', accuracy/test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95       122\n",
      "         1.0       0.99      0.98      0.99       135\n",
      "         2.0       0.84      0.91      0.87       110\n",
      "         3.0       0.95      0.79      0.87       106\n",
      "         4.0       0.98      0.90      0.94       136\n",
      "         5.0       0.89      0.89      0.89        96\n",
      "         6.0       0.91      0.96      0.93       110\n",
      "         7.0       0.97      0.92      0.94       156\n",
      "         8.0       0.79      0.88      0.83       110\n",
      "         9.0       0.87      0.96      0.91       119\n",
      "\n",
      "    accuracy                           0.92      1200\n",
      "   macro avg       0.92      0.91      0.91      1200\n",
      "weighted avg       0.92      0.92      0.92      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\\n\")\n",
    "print(classification_report(gt_list, pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[116   0   2   0   1   1   1   0   1   0]\n",
      " [  0 132   1   0   0   0   0   0   2   0]\n",
      " [  1   1 100   2   1   0   0   1   3   1]\n",
      " [  0   0   4  84   0   7   0   2   9   0]\n",
      " [  0   0   3   0 123   0   3   0   0   7]\n",
      " [  1   0   1   0   0  85   4   0   4   1]\n",
      " [  1   0   0   0   0   1 106   0   2   0]\n",
      " [  1   0   3   0   0   0   1 143   2   6]\n",
      " [  1   0   4   2   0   2   2   0  97   2]\n",
      " [  0   0   1   0   0   0   0   1   3 114]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\\n\")\n",
    "print(confusion_matrix(gt_list, pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fX0ZbmuQv34y"
   },
   "source": [
    "# Test on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SveRnMdrvx6j"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label :  [9]\n",
      "Ground truth label :  9.0\n"
     ]
    }
   ],
   "source": [
    "TEST_IMG_NO = 100\n",
    "test_img = X_test[TEST_IMG_NO]\n",
    "test_img = np.reshape(test_img, (1,28,28,1)) # adding batch dimension to image\n",
    "plt.imshow(test_img[0,:,:,0])\n",
    "plt.title(\"Test Image\")\n",
    "plt.show()\n",
    "\n",
    "output = test_img.copy()\n",
    "for layer in model:\n",
    "    output = layer.forward(output)\n",
    "pred_label = np.argmax(output, axis=1)\n",
    "gt_label = Y_test[TEST_IMG_NO]\n",
    "\n",
    "print(\"Predicted Label : \", pred_label)\n",
    "print(\"Ground truth label : \", gt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVdA7w98x8zC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label :  [7]\n",
      "Ground truth label :  7.0\n"
     ]
    }
   ],
   "source": [
    "TEST_IMG_NO = 10\n",
    "test_img = X_test[TEST_IMG_NO]\n",
    "test_img = np.reshape(test_img, (1,28,28,1)) # adding batch dimension to image\n",
    "plt.imshow(test_img[0,:,:,0])\n",
    "plt.title(\"Test Image\")\n",
    "plt.show()\n",
    "\n",
    "output = test_img.copy()\n",
    "for layer in model:\n",
    "    output = layer.forward(output)\n",
    "pred_label = np.argmax(output,axis=1)\n",
    "gt_label = Y_test[TEST_IMG_NO]\n",
    "\n",
    "print(\"Predicted Label : \", pred_label)\n",
    "print(\"Ground truth label : \", gt_label)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Manan's Copy of DL_Assign5Qns.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02bd46670bb84d1c91cf1b3caa0c7e24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7910066bb3434834b9b6d31fd45b8d64",
      "placeholder": "",
      "style": "IPY_MODEL_8441c2a371e14f8e85ff8ba166884fbd",
      "value": " 1348/3200 [05:31&lt;07:22,  4.19it/s]"
     }
    },
    "0d1981de55af4c088695ea8a55076bfb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f853f38f1444a678d71917f339b73fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d1981de55af4c088695ea8a55076bfb",
      "max": 1500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c1954630645448795cda910c64a2e8f",
      "value": 1500
     }
    },
    "1c1954630645448795cda910c64a2e8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "243f976ef6d440189e00df97f0cf467c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "342bcc9d813a45e5ba5e508e971a2778": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": " 42%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc21b29d7f9541e9be6fe4747b6604ac",
      "max": 3200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2fcdf429f2b4e179189fc19b5fde704",
      "value": 1348
     }
    },
    "63c02eeff8074881bbb2ccb6fc3c35b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7910066bb3434834b9b6d31fd45b8d64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8441c2a371e14f8e85ff8ba166884fbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a129cc23368f42e6a4984c3856151768": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_342bcc9d813a45e5ba5e508e971a2778",
       "IPY_MODEL_02bd46670bb84d1c91cf1b3caa0c7e24"
      ],
      "layout": "IPY_MODEL_d4783a4da9464489a9de103a8b1e29f0"
     }
    },
    "a37011d0c0f04548a748d2b18785ec96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_243f976ef6d440189e00df97f0cf467c",
      "placeholder": "",
      "style": "IPY_MODEL_63c02eeff8074881bbb2ccb6fc3c35b8",
      "value": " 1500/1500 [02:53&lt;00:00,  8.63it/s]"
     }
    },
    "a4c348bc738a483f8dafdd01bc6cf7ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0f853f38f1444a678d71917f339b73fe",
       "IPY_MODEL_a37011d0c0f04548a748d2b18785ec96"
      ],
      "layout": "IPY_MODEL_fa74b47a01c842e9ad2352f42fd49944"
     }
    },
    "d4783a4da9464489a9de103a8b1e29f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc21b29d7f9541e9be6fe4747b6604ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2fcdf429f2b4e179189fc19b5fde704": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fa74b47a01c842e9ad2352f42fd49944": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
